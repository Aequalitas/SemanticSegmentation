{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras import metrics\n",
    "from keras.layers import Dense, Softmax, Conv2D, Input, Flatten, Lambda, MaxPooling2D, BatchNormalization, Conv2DTranspose, Dropout\n",
    "from IPython.display import display \n",
    "import metricsSemSeg\n",
    "\n",
    "CLASSTORGB = [[0,0,0],[255,255,255]]\n",
    "NNName = \"xceptionNet\"\n",
    "DATASET = \"Seagrass\"\n",
    "CLASSES = 2\n",
    "BSIZE = 4\n",
    "X = 256\n",
    "Y = 128\n",
    "CLASSWEIGHTS = [0.1, 1.0]\n",
    "TRAINSIZE = 4223/BSIZE\n",
    "VALSIZE = 610/BSIZE\n",
    "TESTSIZE = 1204/BSIZE\n",
    "TRAINPATH = \"images/\"\n",
    "LABELPATH = \"ground-truth/\"\n",
    "DATASETPATH = \"../data/\"+DATASET+\"/\"\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "filepath = \"../models/keras/\"+NNName+str(X)+str(Y)+DATASET+\"LR\"+str(LR)+\"batch\"+str(BSIZE)+\".h5\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "# semantic segmentation metrics\n",
    "class metricsSS(object):\n",
    "\n",
    "    def __init__(self, num_classes, _bsize):\n",
    "        super().__init__()\n",
    "        self.classes = num_classes\n",
    "        self.batchSize = _bsize\n",
    "        self.pA = metricsSemSeg.pixel_accuracy\n",
    "        self.mA = metricsSemSeg.mean_accuracy\n",
    "        self.mIoU = metricsSemSeg.mean_IU\n",
    "        self.fwmIoU = metricsSemSeg.frequency_weighted_IU\n",
    "\n",
    "    def preProcessKerasInput(self, _pred, _true):\n",
    "            pred = K.argmax(_pred, axis=2)\n",
    "            true = K.argmax(_true, axis=2)\n",
    "            #pred = K.cast(pred, tf.float32)\n",
    "            #true = K.cast(true, tf.float32)\n",
    "            return pred, true\n",
    "\n",
    "    def meanIoU(self, y_true, y_pred):\n",
    "        metric = 0.0\n",
    "        for b in range(self.batchSize):\n",
    "            pred, true = self.preProcessKerasInput(y_pred[b], y_true[b])\n",
    "            metric += tf.py_func(self.mIoU, [pred, true], tf.float32)\n",
    "\n",
    "        return metric/self.batchSize\n",
    "\n",
    "    def frequencyWeightedUI(self, y_true, y_pred):\n",
    "        metric = 0.0\n",
    "        for b in range(self.batchSize):\n",
    "            pred, true = self.preProcessKerasInput(y_pred[b], y_true[b])\n",
    "            metric += tf.py_func(self.fwmIoU, [pred, true], tf.float32)\n",
    "\n",
    "        return metric/self.batchSize\n",
    "\n",
    "\n",
    "    def pixelAccuracy(self, y_true, y_pred):\n",
    "        metric = 0.0\n",
    "        for b in range(self.batchSize):\n",
    "            pred, true = self.preProcessKerasInput(y_pred[b], y_true[b])\n",
    "            metric += tf.py_func(self.pA, [pred, true], tf.float32)\n",
    "\n",
    "        return metric/self.batchSize\n",
    "\n",
    "\n",
    "    def meanAccuracy(self, y_true, y_pred):\n",
    "        metric = 0.0\n",
    "        for b in range(self.batchSize):\n",
    "            pred, true = self.preProcessKerasInput(y_pred[b], y_true[b])\n",
    "            metric += tf.py_func(self.mA, [pred, true], tf.float32)\n",
    "\n",
    "        return metric/self.batchSize\n",
    "\n",
    "\n",
    "##################### Pixel Deconvolution\n",
    "# This module realizes the three methods proposed in paper\n",
    "# [Pixel Deconvolutional Networks] (https://arxiv.org/abs/1705.06820)\n",
    "# https://github.com/HongyangGao/PixelDCN/blob/master/utils/pixel_dcn.py\n",
    "\n",
    "\n",
    "def pixel_dcl(inputs, out_num, kernel_size, scope, activation_fn=tf.nn.relu,\n",
    "              d_format='NHWC'):\n",
    "    \"\"\"\n",
    "    inputs: input tensor\n",
    "    out_num: output channel number\n",
    "    kernel_size: convolutional kernel size\n",
    "    scope: operation scope\n",
    "    activation_fn: activation function, could be None if needed\n",
    "    \"\"\"\n",
    "    \n",
    "    axis = (d_format.index('H'), d_format.index('W'))\n",
    "    conv0 = conv2d(inputs, out_num, kernel_size,\n",
    "                   scope+'/conv0', d_format=d_format)\n",
    "    conv1 = conv2d(conv0, out_num, kernel_size,\n",
    "                   scope+'/conv1', d_format=d_format)\n",
    "    dilated_conv0 = dilate_tensor(conv0, axis, (0, 0), scope+'/dialte_conv0')\n",
    "    dilated_conv1 = dilate_tensor(conv1, axis, (1, 1), scope+'/dialte_conv1')\n",
    "    conv1 = tf.add(dilated_conv0, dilated_conv1, scope+'/add1')\n",
    "    with tf.variable_scope(scope+'/conv2'):\n",
    "        shape = list(kernel_size) + [out_num, out_num]\n",
    "        weights = tf.get_variable(\n",
    "            'weights', shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        weights = tf.multiply(weights, get_mask(shape, scope))\n",
    "        strides = [1, 1, 1, 1]\n",
    "        conv2 = tf.nn.conv2d(conv1, weights, strides, padding='SAME',\n",
    "                             data_format=d_format)\n",
    "        conv2 = Conv2D(\n",
    "                weights,\n",
    "                strides=stride,\n",
    "                padding='same',\n",
    "                data_format=\"channels_last\"\n",
    "                )\n",
    "        conv2.input = conv1\n",
    "        \n",
    "    outputs = tf.add(conv1, conv2.output, name=scope+'/add2')\n",
    "    if activation_fn:\n",
    "        outputs = activation_fn(outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def combine(tensors, action, axis, name):\n",
    "    if action == 'concat':\n",
    "        return tf.concat(tensors, axis, name=name)\n",
    "    else:\n",
    "        return tf.add_n(tensors, name=name)\n",
    "\n",
    "def conv2d(inputs, out_num, kernel_size, scope, stride=1, d_format='NHWC'):\n",
    "    #outputs = tf.contrib.layers.conv2d(\n",
    "    #    inputs, out_num, kernel_size, scope=scope, stride=stride,\n",
    "    #    data_format=d_format, activation_fn=None, biases_initializer=None)\n",
    "    \n",
    "    outputs = Conv2D(\n",
    "                out_num,\n",
    "                kernel_size,\n",
    "                strides=stride,\n",
    "                padding='same',\n",
    "                data_format=\"channels_last\",\n",
    "                use_bias=False,\n",
    "                kernel_initializer='glorot_uniform'\n",
    "                )\n",
    "    outputs.input = inputs\n",
    "    \n",
    "    return outputs.output\n",
    "\n",
    "\n",
    "def conv3d(inputs, out_num, kernel_size, scope):\n",
    "    shape = list(kernel_size) + [inputs.shape[-1].value, out_num]\n",
    "    weights = tf.get_variable(\n",
    "        scope+'/conv/weights', shape, initializer=tf.truncated_normal_initializer())\n",
    "    #outputs = tf.nn.conv3d(\n",
    "    #    inputs, weights, (1, 1, 1, 1, 1), padding='SAME', name=scope+'/conv')\n",
    "    \n",
    "    outputs = keras.layers.Conv3D(\n",
    "        weights,\n",
    "        strides=(1, 1, 1, 1, 1),\n",
    "        padding='same'\n",
    "        )\n",
    "    \n",
    "    outputs.input = inputs\n",
    "    return outputs.output\n",
    "\n",
    "\n",
    "def get_mask(shape, scope):\n",
    "    new_shape = (np.prod(shape[:-2]), shape[-2], shape[-1])\n",
    "    mask = np.ones(new_shape, dtype=np.float32)\n",
    "    for i in range(0, new_shape[0], 2):\n",
    "        mask[i, :, :] = 0\n",
    "    mask = np.reshape(mask, shape, 'F')\n",
    "    return tf.constant(mask, dtype=tf.float32, name=scope+'/mask')\n",
    "\n",
    "\n",
    "def dilate_tensor(inputs, axes, shifts, scope):\n",
    "    for index, axis in enumerate(axes):\n",
    "        eles = tf.unstack(inputs, axis=axis, name=scope+'/unstack%s' % index)\n",
    "        zeros = tf.zeros_like(\n",
    "            eles[0], dtype=tf.float32, name=scope+'/zeros%s' % index)\n",
    "        for ele_index in range(len(eles), 0, -1):\n",
    "            eles.insert(ele_index-shifts[index], zeros)\n",
    "        inputs = tf.stack(eles, axis=axis, name=scope+'/stack%s' % index)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def shift_tensor(inputs, axes, row_shift, column_shift, scope):\n",
    "    if row_shift:\n",
    "        rows = tf.unstack(inputs, axis=axes[0], name=scope+'/rowsunstack')\n",
    "        row_zeros = tf.zeros_like(\n",
    "            rows[0], dtype=tf.float32, name=scope+'/rowzeros')\n",
    "        rows = rows[row_shift:] + [row_zeros]*row_shift\n",
    "        inputs = tf.stack(rows, axis=axes[0], name=scope+'/rowsstack')\n",
    "    if column_shift:\n",
    "        columns = tf.unstack(\n",
    "            inputs, axis=axes[1], name=scope+'/columnsunstack')\n",
    "        columns_zeros = tf.zeros_like(\n",
    "            columns[0], dtype=tf.float32, name=scope+'/columnzeros')\n",
    "        columns = columns[column_shift:] + [columns_zeros]*column_shift\n",
    "        inputs = tf.stack(columns, axis=axes[1], name=scope+'/columnsstack')\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def pixelDeconv(x, depth, scope):\n",
    "    return pixel_dcl(x, depth, [3,3], scope)\n",
    "\n",
    "def convS(f, model):\n",
    "    model.add(Conv2D(f, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout())\n",
    "    \n",
    "def deconv(f, model):\n",
    "    model.add(Conv2DTranspose(f, 3, strides=2, padding='same', activation=\"relu\"))\n",
    "\n",
    "\n",
    "def conv(first=False, units=128, f=3, dilation=1, last=False):\n",
    "    if first :  \n",
    "        return Conv2D(\n",
    "            units,\n",
    "            f,\n",
    "            input_shape=(Y, X, 3),\n",
    "            strides=(1, 1),\n",
    "            padding='same',\n",
    "            activation=\"relu\" if not last else \"softmax\",\n",
    "            use_bias=True,\n",
    "            dilation_rate=dilation,\n",
    "            data_format=\"channels_last\",\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=keras.initializers.Constant(value=0.1)\n",
    "        )\n",
    "    else:\n",
    "        return Conv2D(\n",
    "            units if not last else CLASSES,\n",
    "            3 if not last else 1,\n",
    "            strides=(1, 1),\n",
    "            padding='same',\n",
    "            activation=\"relu\",\n",
    "            use_bias=True,\n",
    "            data_format=\"channels_last\",\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=keras.initializers.Constant(value=0.1)\n",
    "        )\n",
    "\n",
    "def deConv(depth):\n",
    "    return Conv2DTranspose(\n",
    "        depth,\n",
    "        3,\n",
    "        strides=(2, 2),\n",
    "        padding='same',\n",
    "        data_format=\"channels_last\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        bias_initializer=keras.initializers.Constant(value=0.1)\n",
    "    )\n",
    "\n",
    "    \n",
    "def netFCN():\n",
    "    model = Sequential()\n",
    "    # layers\n",
    "    # encoding\n",
    "    model.add(conv(first=True))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.3))\n",
    "\n",
    "\n",
    "    model.add(conv(units=128))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.3))\n",
    "\n",
    "    model.add(conv(units=256))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    \n",
    "    model.add(conv(units=512))\n",
    "    L = BatchNormalization()\n",
    "    model.add(L)\n",
    "\n",
    "    # decoding\n",
    "    model.add(deConv(512))\n",
    "    model.add(deConv(256))\n",
    "    #model.add(deConv(128))\n",
    "    #model.add(keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "    #model.add(keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "\n",
    "    #L = Lambda(lambda input: pixelDeconv(tf.convert_to_tensor(input), 512, \"dec1\"))\n",
    "    #model.add(L)\n",
    "    #L = Lambda(lambda input: pixelDeconv(tf.convert_to_tensor(input), 256, \"dec2\"))\n",
    "    #model.add(L)\n",
    "    #L = Lambda(pixelDeconv(L.output, 128, \"dec3\"))\n",
    "    #model.add(L)\n",
    "    \n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(conv(last=True))\n",
    "    model.add(Softmax())\n",
    "\n",
    "    return model\n",
    "\n",
    "def dilNet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(conv(first=True))\n",
    "    model.add(conv(units=128))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(conv(units=128))\n",
    "    model.add(conv(units=256))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "        \n",
    "    model.add(conv(units=256))\n",
    "    model.add(conv(units=256))\n",
    "    model.add(conv(units=256, f=1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(conv(units=512, dilation=2))\n",
    "    model.add(conv(units=512, dilation=2))\n",
    "    model.add(conv(units=512, f=1, dilation=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(conv(units=512, dilation=4))\n",
    "    model.add(conv(units=512, dilation=4))\n",
    "    model.add(conv(units=512, f=1, dilation=4))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(deConv(512))\n",
    "    model.add(deConv(256))\n",
    "\n",
    "    #model.add(keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "    #model.add(keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "\n",
    "    model.add(conv(last=True))\n",
    "    model.add(Softmax())    \n",
    "    return model\n",
    "\n",
    "def mobileNet_V2_SS(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        input_shape=inputShape,\n",
    "        alpha=1.0,\n",
    "        depth_multiplier=1,\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "        \n",
    "    ))\n",
    "    \n",
    "    deconv(320, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(128, model)\n",
    "    model.add(conv(last=True))\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def inceptionResnet_SS(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "        input_shape=inputShape,\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    ))\n",
    "    \n",
    "    deconv(320, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(128, model)\n",
    "    model.add(conv(last=True))\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model\n",
    "              \n",
    "def xception_SS(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.xception.Xception(\n",
    "        input_shape=inputShape,\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    ))\n",
    "    \n",
    "    deconv(320, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(128, model)\n",
    "    model.add(conv(last=True))\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model\n",
    "              \n",
    "def nasNet_SS(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.nasnet.NASNetLarge(\n",
    "        input_shape=inputShape,\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    ))\n",
    "    \n",
    "    deconv(320, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(256, model)\n",
    "    deconv(128, model)\n",
    "    convS(CLASSES, model)\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model\n",
    "\n",
    "class DataSequence(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, batchSize, trainType):\n",
    "        self.dataSetPath = DATASETPATH\n",
    "        \n",
    "        if trainType == \"train\":\n",
    "            jsonData = json.load(open(DATASETPATH+\"train.json\"))\n",
    "            self.x = list(map(lambda i:os.path.basename(i[\"image\"]) if i[\"depth\"] <= float(6) else None, jsonData))\n",
    "            self.y = list(map(lambda i:os.path.basename(i[\"ground-truth\"]) if i[\"depth\"] <= float(6) else None, jsonData))\n",
    "            TRAINSIZE = len(self.x)\n",
    "            \n",
    "            \n",
    "        elif trainType == \"validation\":\n",
    "            jsonData = json.load(open(DATASETPATH+\"test.json\"))\n",
    "            self.x = list(map(lambda i:os.path.basename(i[\"image\"]), jsonData))\n",
    "            self.y = list(map(lambda i:os.path.basename(i[\"ground-truth\"]), jsonData))\n",
    "            VALSIZE = len(self.x)\n",
    "        \n",
    "        elif trainType == \"test\":\n",
    "            jsonData = json.load(open(DATASETPATH+\"validate.json\"))\n",
    "            self.x = list(map(lambda i:os.path.basename(i[\"image\"]), jsonData))\n",
    "            self.y = list(map(lambda i:os.path.basename(i[\"ground-truth\"]), jsonData))\n",
    "            TESTSIZE = len(self.x)\n",
    "        \n",
    "        else:\n",
    "            raise \"unknown dataset type, valid are train, validation and test\"\n",
    "    \n",
    "        \n",
    "        self.batch_size = batchSize\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        imgBatch = None\n",
    "        labelImgBatch = None\n",
    "        \n",
    "        for b in range(self.batch_size):\n",
    "            #  loading train and label image\n",
    "            img = cv2.imread(self.dataSetPath+TRAINPATH+self.x[idx+b])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (X, Y), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            labelImg = cv2.imread(self.dataSetPath+LABELPATH+self.y[idx+b])\n",
    "            labelImg = cv2.cvtColor(labelImg, cv2.COLOR_BGR2RGB)\n",
    "            labelImg = cv2.resize(labelImg, (X, Y), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "           # if CLASSES == 2:\n",
    "            #    labelImg[(labelImg  >= 128).all(-1)] = [255,255,255]\n",
    "             #   labelImg[(labelImg  <= 127).all(-1)] = [0,0,0]\n",
    "\n",
    "\n",
    "            #print(self.dataSetPath+TRAINPATH+self.x[idx], self.dataSetPath+LABELPATH+self.y[idx])\n",
    "            #display(Image.fromarray(img, \"RGB\"))\n",
    "            #display(Image.fromarray(labelImg, \"RGB\"))\n",
    "\n",
    "            # process train and label image\n",
    "            img = ((img - img.mean()) / img.std()).astype(np.float32)\n",
    "            img = np.array(img)\n",
    "            img = np.reshape(img, (1,Y,X,3))\n",
    "\n",
    "\n",
    "\n",
    "            for rgbIdx, rgbV in enumerate(CLASSTORGB):\n",
    "                labelImg[(labelImg == rgbV).all(-1)] = rgbIdx\n",
    "\n",
    "\n",
    "            labelImg = labelImg[:,:,0].astype(np.int32)\n",
    "            labelImg = np.reshape(labelImg, (1,Y,X,1))\n",
    "\n",
    "\n",
    "            # dont know why but there are(some datasets) rgb values which are not assigned to a class\n",
    "            # because of this these values are not replaced with their assigned class and\n",
    "            # have to be removed as in assigned to class zero aka black\n",
    "            #print(\"UNIQUE RGB VALUES\", np.unique(np.array(img).reshape((int(6291456/3), 3)), axis=0))\n",
    "\n",
    "            labelImg[(labelImg >= CLASSES)] = 0\n",
    "\n",
    "            #onehot = keras.utils.to_categorical(labelImg, num_classes=2, dtype='float32')\n",
    "            #print(img.shape, labelImg.shape)\n",
    "            #calculcate the weights for the current image\n",
    "            #sampleWeights = onehot * [0.1, 1.0]\n",
    "            #sampleWeights = np.sum(sampleWeights, axis=3)\n",
    "            #sampleWeights = sampleWeights.reshape((self.batch_size,224,224,1))\n",
    "        \n",
    "            if imgBatch is None:\n",
    "                imgBatch = img\n",
    "                labelImgBatch = labelImg\n",
    "            else:\n",
    "                imgBatch = np.concatenate((imgBatch, img), axis=0)\n",
    "                labelImgBatch = np.concatenate((labelImgBatch, labelImg), axis=0)\n",
    "            \n",
    "        return imgBatch, labelImgBatch#, sampleWeights\n",
    "    \n",
    "\n",
    "    \n",
    "def pred(fileName, debug=True):\n",
    "    predImg = cv2.imread(\"../results/\"+fileName)\n",
    "    predImg = cv2.cvtColor(predImg, cv2.COLOR_BGR2RGB)\n",
    "    predImg = cv2.resize(predImg, (X, Y), interpolation=cv2.INTER_NEAREST)\n",
    "    predImg = np.expand_dims(((predImg  - predImg.mean()) / predImg.std()).astype(np.float32), axis=0)\n",
    "    predClasses = model.predict(predImg)\n",
    "    predClasses = np.argmax(predClasses, axis=3).flatten()\n",
    "    #print(predClasses.shape, np.bincount(predClasses), predClasses)\n",
    "    predImg = np.zeros((X*Y,3))\n",
    "\n",
    "    for idx, p in enumerate(predClasses):\n",
    "        predImg[idx] = CLASSTORGB[p]\n",
    "         \n",
    "   \n",
    "    predImg = predImg.reshape((Y, X, 3)).astype(\"uint8\")\n",
    "    \n",
    "    if debug:\n",
    "        display(Image.fromarray(predImg, \"RGB\"))\n",
    "        \n",
    "class regularPred(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred(\"predictSeagrass.jpg\")\n",
    "\n",
    "    #def on_batch_end(self, batch, logs={}):\n",
    "    #    if batch % 500 == 0:\n",
    "    #        pred(\"predict.jpg\")\n",
    "        \n",
    "    \n",
    "# in case class weights are needed\n",
    "def sparse_crossentropy_weighted(ground_truth, predictions):\n",
    "    \n",
    "    ground_truth = tf.cast(ground_truth, tf.int32)\n",
    "        \n",
    "    #onehot_labels = tf.one_hot(tf.squeeze(ground_truth,3), CLASSES)\n",
    "    #weights = onehot_labels * CLASSWEIGHTS\n",
    "    #weights = tf.reduce_sum(weights, 3)\n",
    "    \n",
    "    return tf.reduce_mean(\n",
    "        tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels=ground_truth,\n",
    "                        logits=predictions))\n",
    "     #                   weights=weights))\n",
    "\n",
    "def getModel(modelName):\n",
    "    import os\n",
    "    from keras.models import load_model\n",
    "\n",
    "    metricsPA = metricsSS(CLASSES, BSIZE).pixelAccuracy\n",
    "    metricsMA = metricsSS(CLASSES, BSIZE).meanAccuracy\n",
    "    metricsMIOU = metricsSS(CLASSES, BSIZE).meanIoU\n",
    "    metricsFWMIOU = metricsSS(CLASSES, BSIZE).frequencyWeightedUI\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        model = load_model(filepath, custom_objects={\n",
    "                                        \"sparse_crossentropy_weighted\":sparse_crossentropy_weighted,\n",
    "                                        'pixelAccuracy': metricsPA,\n",
    "                                        \"meanAccuracy\": metricsMA,\n",
    "                                        \"meanIoU\": metricsMIOU,\n",
    "                                        \"frequencyWeightedUI\": metricsFWMIOU\n",
    "                                    }\n",
    "                          )\n",
    "\n",
    "        print(\"Model loaded from h5 file\")\n",
    "    else:\n",
    "        if modelName == \"deeplabv3\":\n",
    "            from nets.deepLabv3Keras import Deeplabv3\n",
    "            model = Deeplabv3(weights=None, backbone=\"xception\", input_shape=(Y,X,3), classes=CLASSES, OS=8)  \n",
    "        elif modelName == \"mobilenetv2\":\n",
    "            model = mobileNet_V2_SS((Y,X,3))\n",
    "        elif modelName ==\"FCN\":\n",
    "            model = netFCN()\n",
    "        elif modelName ==\"dilNet\":\n",
    "            model = dilNet()\n",
    "        elif modelName ==\"NASNet\":\n",
    "            model = nasNet_SS((Y,X,3))\n",
    "        elif modelName ==\"inceptionresnetNet\":\n",
    "            model = inceptionResnet_SS((Y,X,3))\n",
    "        elif modelName ==\"xceptionNet\":\n",
    "            model = xception_SS((Y,X,3)) \n",
    "        else:\n",
    "            raise \"no right modelname given\"\n",
    "\n",
    "        print(\"Fresh model loaded from architecture\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from h5 file\n",
      "Model compiled...\n",
      "Epoch 1/100\n",
      "1056/1055 [==============================] - 114s 108ms/step - loss: 0.3576 - val_loss: 0.3687\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAACACAIAAABr1yBdAAADN0lEQVR4nO3cy27bMBBAUavI//8yu3BjFGnqUC9yOHPOIqvAEaC5Imkj3h6TtNZm/Wl42rbt1+xrgGlaa9MC2LZt1p+GFysApc0MwCLAdCFG0IGYWWyBKE0AJPd+px1iC/SwC2KSKCuAAzFTRAngMbsBBdYU664P2wj1jLtd2Yq2bWutPX92/f7dF7TXgLHrf9hrIL1wATzuHLsD+xwN5BboDPBy+XZ8+3TtyxLNgVscMYDH58he9VKXvA4prTEch/chl0y/XVBiH7MvoNdrlHtP9x78dFh1Sr7N4L6htwhktWoAj7+GcsDDXgBZBT0E93jO/Zitjg1VVu7rDtaBfBZeAeA8AVCaAHZwEshHAJQmAEoTAKUJgNIEsI9zcDICoDQBUJoAKE0AlCaA3ZyDMxEApQmA0gSwm/8KyEQAlCYAShPAPvY/yQiA0gSwg8d/PgLoZfpTEgClCaCLx39WAviZ6U9MAD8w/bkJgNIEQGkCoDQBvOMAkJ4AKE0AlCYAShMApQngHV8AkZ4AKE0AlCYAShPADxwDcnN3e/lUOCUB7CODZARwkBJycAY4yNkgBwEcp4EEBEBpAjjFIrA6AZylgaUJ4AIaWJc7dyXvjS7HCnAlS8FyBHAxDaxFANfTwEIEQGkCuIVFYBUCuIsGliAAShPAjSwC8QmA0gRwL4tAcAK4nQYiEwClCWAEi0BYAqA0AQxiEYhJAJQmAEoTAKUJgNIEQGkCoDQBUJoAKE0AlJbt48kvX00V5/NX35kVU5T5OOn9eEXIQAAxzZ+Mw/aO1NwMBBBToTNAa80U8sV6K8D5IX4uBa21YWuC8ML6mH0BExhHXhbbAl07u2NK0FtkKwVwxyQNmM4I70HxPwvcmzFP0JvG1OM/uJVWALicAP7wJmlN0QMYPJQrHrI5I/QZYPoAnTkYTL94esQNIM4AHcggzsXzXsQAYk5PfwYxr59vRT8DxNE51qZ/LeFWgPgD9L+lIP6V869YAZghBgu0BTL9jBcoABhv8hbIU5+5rACUJgBKmxmA/Q/TTQvA9BOBLRClCYDS5gRg/0MQVgBKmxCAxz9xjA7A9BOKLRClDQ3A459ofgOChOG8kovFoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x128 at 0x7F720DB80FD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36866, saving model to ../models/keras/xceptionNet256128SeagrassLR0.001batch4.h5\n",
      "Epoch 2/100\n",
      " 604/1055 [================>.............] - ETA: 41s - loss: 0.3440"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "model = getModel(NNName)\n",
    "        \n",
    "#model.summary()\n",
    "model.compile(\n",
    "                loss=sparse_crossentropy_weighted,\n",
    "                optimizer=keras.optimizers.Nadam(lr=LR),\n",
    "                metrics=[]\n",
    "            )\n",
    "\n",
    "print(\"Model compiled...\")\n",
    "\n",
    "modelCheckpointer = keras.callbacks.ModelCheckpoint(\n",
    "                                    filepath,\n",
    "                                    monitor='val_loss',\n",
    "                                    verbose=1,\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False,\n",
    "                                    mode='min',\n",
    "                                    period=1)\n",
    "\n",
    "earlyStopper = keras.callbacks.EarlyStopping(\n",
    "                                          monitor='val_loss',\n",
    "                                          min_delta=0.0001,\n",
    "                                          patience=10,\n",
    "                                          verbose=1,\n",
    "                                          mode='min'\n",
    "                                    )\n",
    "lrReducer = keras.callbacks.ReduceLROnPlateau(\n",
    "                                    monitor='val_loss',\n",
    "                                    factor=0.1,\n",
    "                                    patience=5,\n",
    "                                    verbose=1,\n",
    "                                    mode=\"min\",\n",
    "                                    min_delta=0.0001,\n",
    "                                    cooldown=0,\n",
    "                                    min_lr=0)\n",
    "\n",
    "history = model.fit_generator(\n",
    "        DataSequence(BSIZE, \"train\"),\n",
    "        steps_per_epoch=TRAINSIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,\n",
    "        shuffle=True,\n",
    "        validation_data=DataSequence(BSIZE,\"validation\"),\n",
    "        validation_steps=VALSIZE,\n",
    "        callbacks=[\n",
    "            regularPred(),\n",
    "            modelCheckpointer,\n",
    "            earlyStopper,\n",
    "            lrReducer\n",
    "            ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "testloss = model.evaluate_generator(\n",
    "    DataSequence(BSIZE,\"test\"),\n",
    "    steps=TESTSIZE,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(testloss)\n",
    "model.save(\"lastModel\"+filepath)\n",
    "print(\"Last model saved....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "from metricsSemSeg import pixel_accuracy, mean_accuracy, mean_IU, frequency_weighted_IU\n",
    "\n",
    "config = json.load(open(\"nets/netFCNConfig.json\"))\n",
    "# load data object initially which provides training and test data loader\n",
    "data = Data(\"../data/\"+DATASET+\"/configData\"+DATASET+\".json\")\n",
    "totalCorrect = 0\n",
    "totalCount = TESTSIZE*X*Y*3\n",
    "\n",
    "totalPAcc = 0.0\n",
    "totalMAcc = 0.0\n",
    "totalMIU = 0.0\n",
    "totalFWIU = 0.0\n",
    "\n",
    "i = 0\n",
    "model = getModel(NNName)\n",
    "\n",
    "for labelData, imgData in data.getNextBatchTest(BSIZE, TESTSIZE*BSIZE):\n",
    "\n",
    "    # upper = config[\"batchSize\"]*i\n",
    "    # lower = config[\"batchSize\"]*(i-1)  \n",
    "\n",
    "    # if upper <= totalTestCount:\n",
    "    #     images = imgData[lower:upper]\n",
    "    #     labels = labelData[lower:upper]\n",
    "\n",
    "    #     totalCount += labels.size\n",
    "    \n",
    "        print(imgData.shape, labelData.shape)\n",
    "\n",
    "        predClasses = model.predict_on_batch(imgData)\n",
    "\n",
    "        predClasses = np.squeeze(predClasses[0])\n",
    "        predClasses = np.argmax(predClasses, axis=2)\n",
    "        labelData = np.squeeze(labelData[0])\n",
    "        \n",
    "        if i % 100/BSIZE == 0:\n",
    "            print(\"Image \", i, \" evaluated...\")\n",
    "\n",
    "        #print(predClasses.shape, labelData.shape)\n",
    "\n",
    "        totalPAcc = pixel_accuracy(predClasses, labelData) if totalPAcc == 0.0 else  (totalPAcc + pixel_accuracy(predClasses, labelData))/2\n",
    "        totalMAcc = mean_accuracy(predClasses, labelData) if totalMAcc == 0.0 else  (totalMAcc + mean_accuracy(predClasses, labelData))/2\n",
    "        totalMIU = mean_IU(predClasses, labelData) if totalMIU == 0.0 else  (totalMIU + mean_IU(predClasses, labelData))/2\n",
    "        totalFWIU = frequency_weighted_IU(predClasses, labelData) if totalFWIU == 0.0 else  (totalFWIU + frequency_weighted_IU(predClasses, labelData))/2\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "print(\"Pixel accuracy: \", totalPAcc ,\" || Mean accuracy: \", totalMAcc ,\" || Mean intersection union:\", totalMIU ,\" || frequency weighted IU: \", totalFWIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "#plt.plot(history.history['pixelAccuracy'])\n",
    "#plt.plot(history.history['val_pixelAccuracy'])\n",
    "#plt.title('pixel accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train',\"val\"], loc='upper left')\n",
    "#plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', \"val\"], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for mean iou\n",
    "#plt.plot(history.history['meanIoU'])\n",
    "#plt.plot(history.history['val_meanIoU'])\n",
    "#plt.title('model mean IoU')\n",
    "#plt.ylabel('mean_iou')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', \"val\"], loc='upper left')\n",
    "#plt.show()\n",
    "#plt.plot(history.history['meanAccuracy'])\n",
    "#plt.plot(history.history['val_meanAccuracy'])\n",
    "#plt.title('model meanAccuracy')\n",
    "#plt.ylabel('meanAccuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', \"val\"], loc='upper left')\n",
    "#plt.show()\n",
    "#plt.plot(history.history['frequencyWeightedUI'])\n",
    "#plt.plot(history.history['val_frequencyWeightedUI'])\n",
    "#plt.title('model frequencyWeightedUI')\n",
    "#plt.ylabel('frequencyWeightedUI')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', \"val\"], loc='upper left')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
