{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "PATH = \"../data/Airbus/\"\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display \n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  192556\n",
      "ImageId          231723\n",
      "EncodedPixels     81723\n",
      "dtype: int64 42556\n"
     ]
    }
   ],
   "source": [
    "trainImgFileNames = os.listdir(PATH+\"train_v2/\")\n",
    "print(\"dataset size: \", len(trainImgFileNames))\n",
    "trainLabels = pd.read_csv(PATH+\"train_ship_segmentations_v2.csv\")\n",
    "trainImgFileNames = trainLabels[(pd.notna(trainLabels[\"EncodedPixels\"]))]\n",
    "trainImgFileNames = np.unique(trainImgFileNames[\"ImageId\"].values)\n",
    "print(trainLabels.count(), len(trainImgFileNames))\n",
    "#trainLabels = trainLabels[trainLabels[\"ImageId\"].isin(trainImgFileNames)]\n",
    "#print(trainLabels[(pd.isna(trainLabels[\"EncodedPixels\"]))].groupby(\"ImageId\").first()[:10])\n",
    "X = 256\n",
    "Y = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns batched rgb input images\n",
    "def getImageData(fileName):\n",
    "    img = cv2.imread(PATH+\"/train_v2/\"+fileName)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = cv2.resize(img, (X, Y), interpolation=cv2.INTER_NEAREST)\n",
    "    img = ((img - img.mean()) / img.std()).astype(np.float32)\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "# returns batched label masks from runlength encodings\n",
    "def getLabelData(fileName):\n",
    "    img = np.zeros((X*Y), dtype=np.uint8)\n",
    "    rLen = trainLabels[trainLabels[\"ImageId\"] == fileName][\"EncodedPixels\"]\n",
    "    #print(fileName, \": \", rLen.size)\n",
    "    if not rLen.isnull().values.any():\n",
    "        # for multiple segments\n",
    "        for s in range(rLen.size):\n",
    "            vals = np.array(rLen.values[s].split(\" \"), dtype=np.int32)\n",
    "            starts = vals[::2]\n",
    "            ends = np.add(vals[::2],vals[1::2])\n",
    "            for idx in range(starts.size):\n",
    "                img[starts[idx]:ends[idx]] = 1\n",
    "\n",
    "    # extend to image with 3 channels\n",
    "    #imgConc = img.copy()\n",
    "    #for d in range(2):\n",
    "     #   imgConc = np.concatenate((imgConc, img), axis=0)\n",
    "\n",
    "    # tranpose to run-lengh encoding direction\n",
    "    return np.array(img.reshape((X,Y)).T)\n",
    "\n",
    "#MAX_IMAGES = 12\n",
    "\n",
    "#x_valid = getImageData(trainImgFileNames[66:66+MAX_IMAGES])\n",
    "#y_valid = getLabelData(trainImgFileNames[66:66+MAX_IMAGES])\n",
    "    \n",
    "#print(x_valid.shape, y_valid.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STRIDE = 2\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "      #initial = tf.truncated_normal(shape, stddev=0.1, name=name)\n",
    "      #return tf.Variable(initial)\n",
    "      with tf.variable_scope(\"\", reuse=tf.AUTO_REUSE):\n",
    "            return tf.get_variable(name, shape=shape,\n",
    "              initializer=tf.contrib.layers.xavier_initializer())#tf.initializers.orthogonal())\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    with tf.variable_scope(\"\", reuse=tf.AUTO_REUSE):\n",
    "        initial = tf.constant(0.1, shape=shape, name=name)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "def conv(input, filter, name, pad=\"SAME\", dilation=0, dropR=0.3):\n",
    "    f = weight_variable(filter, name+\"f1\")\n",
    "\n",
    "    if not dilation > 0:\n",
    "        conv = tf.nn.conv2d(input, f, strides=[1,1,1,1], padding=pad, name=name)\n",
    "    else:\n",
    "        conv = tf.nn.atrous_conv2d(input, f, dilation, padding=pad)\n",
    "    \n",
    "    conv_bias = tf.nn.bias_add(conv, bias_variable([filter[3]], name=name+\"b1\"))\n",
    "    batch_norm = tf.contrib.layers.batch_norm(conv_bias)\n",
    "    \n",
    "    relu = tf.nn.relu(batch_norm)\n",
    "    \n",
    "    #if leakyR:\n",
    "    #relu = tf.nn.leaky_relu(batch_norm,alpha=0.2,name=None)\n",
    "\n",
    "    #drop = tf.nn.dropout(relu, dropR)\n",
    "\n",
    "    #print(name +\": \", conv.get_shape())\n",
    "    #tf.summary.scalar(name, tf.reduce_sum(conv))\n",
    "\n",
    "    return relu\n",
    "    \n",
    "def pool(input, window, stride, poolIndices=False, name=\"POOL\"):\n",
    "    \n",
    "\n",
    "    if poolIndices:\n",
    "        pool = tf.nn.max_pool_with_argmax(\n",
    "                input,\n",
    "                ksize=[1, window, window,1],\n",
    "                strides=[1, stride, stride, 1],\n",
    "                padding=\"SAME\",\n",
    "                name=name\n",
    "            )\n",
    "    else:\n",
    "        pool = tf.nn.max_pool(\n",
    "                input,\n",
    "                ksize=[1, window, window,1],\n",
    "                strides=[1, stride, stride, 1],\n",
    "                padding=\"SAME\",\n",
    "                name=name\n",
    "            )\n",
    "\n",
    "        #print(name + \": \", pool.get_shape())\n",
    "\n",
    "    \n",
    "    return pool\n",
    "    \n",
    "def deconv_filter(shape, name):\n",
    "    \n",
    "    # filter = tf.zeros((\n",
    "    #     shape[0], # height\n",
    "    #     shape[1], # width\n",
    "    #     shape[2], # out channels\n",
    "    #     shape[3] # in channels\n",
    "    #  ), name=name) \n",
    "    \n",
    "    #return tf.Variable(filter)\n",
    "    return tf.get_variable(name, shape=shape,\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def deconv(layer, outputShape, filterShape, name, stride=2):\n",
    "    filter = deconv_filter(filterShape, \"deconvF\"+layer.name[:len(layer.name)-2])\n",
    "\n",
    "    deconv = tf.nn.conv2d_transpose(\n",
    "            layer,\n",
    "            filter,\n",
    "            outputShape,\n",
    "            strides=[1,stride,stride,1],\n",
    "            padding=\"SAME\",\n",
    "            name=name\n",
    "        )\n",
    "    \n",
    "    #print(name +\": \", deconv.get_shape())\n",
    "    return deconv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STRIDE = 2\n",
    "\n",
    "# uNet according to:\n",
    "# Ronneberger et al. - U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "# https://arxiv.org/pdf/1505.04597.pdf \n",
    "\n",
    "def net(image, classes):\n",
    "\n",
    "    #image = tf.image.resize_images(image, [101,101])#, method=ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    bsize = image.get_shape()[0].value\n",
    "    f = 3 # kernel size\n",
    "    #tf.summary.scalar(\"input\", tf.reduce_sum(image))\n",
    "\n",
    "    #encoding - downsampling\n",
    "    # encoding level 1\n",
    "    e1_c1 = conv(image, [f,f,3,1], \"e1_c1\", \"SAME\")\n",
    "    e1_c2 = conv(e1_c1, [f,f,1,64], \"e1_c2\", \"SAME\")\n",
    "    e1_c3 = conv(e1_c2, [f,f,64,64], \"e1_c3\", \"SAME\")\n",
    "    pool1 = pool(e1_c3, 2, 2, name=\"pool1\")\n",
    "\n",
    "    #tf.summary.scalar(\"e1_c1\", tf.reduce_sum(e1_c1))\n",
    "\n",
    "\n",
    "    # encoding level 2\n",
    "    e2_c1 = conv(pool1, [f,f,64,128], \"e2_c1\", \"SAME\")\n",
    "    e2_c2 = conv(e2_c1, [f,f,128,128], \"e2_c2\", \"SAME\")\n",
    "    e2_c3 = conv(e2_c2, [f,f,128,128], \"e2_c3\", \"SAME\")\n",
    "    pool2 = pool(e2_c3, 2, 2, name=\"pool2\")\n",
    "    \n",
    "    tf.summary.scalar(\"e2_c1\", tf.reduce_sum(e2_c1))\n",
    "\n",
    "    # encoding level 3\n",
    "    e3_c1 = conv(pool2, [f,f,128,256], \"e3_c1\", \"SAME\")\n",
    "    e3_c2 = conv(e3_c1, [f,f,256,256], \"e3_c2\", \"SAME\")\n",
    "    e3_c3 = conv(e3_c2, [f,f,256,256], \"e3_c3\", \"SAME\")\n",
    "    pool3 = pool(e3_c3, 2, 2, name=\"pool3\")\n",
    "\n",
    "\n",
    "    #tf.summary.scalar(\"e3_c1\", tf.reduce_sum(e3_c1))\n",
    "\n",
    "    # encoding level 4\n",
    "    e4_c1 = conv(pool3, [f,f,256,512], \"e4_c1\", \"SAME\")\n",
    "    e4_c2 = conv(e4_c1, [f,f,512,512], \"e4_c2\", \"SAME\")\n",
    "    e4_c3 = conv(e4_c2, [f,f,512,512], \"e4_c3\", \"SAME\")\n",
    "    pool4 = pool(e4_c3, 2, 2, name=\"pool4\")\n",
    "\n",
    "    #tf.summary.scalar(\"e4_c1\", tf.reduce_sum(e4_c1))\n",
    "\n",
    "\n",
    "    # encoding level 5\n",
    "    e5_c1 = conv(pool4, [f,f,512,1024], \"e5_c1\", \"SAME\")\n",
    "    e5_c2 = conv(e5_c1, [f,f,1024,1024], \"e5_c2\", \"SAME\")\n",
    "    deOut = [bsize, e5_c2.get_shape()[1].value*STRIDE, e5_c2.get_shape()[2].value*STRIDE, 512]\n",
    "    de_dc1 = deconv(e5_c2, deOut, [f, f, 512, 1024], \"de_dc1\")\n",
    "    #de_dc1 = pixelDeconv.pixel_dcl(e5_c2, 512, [f,f], \"de_dc1\")\n",
    "    #tf.summary.scalar(\"e5_c2\", tf.reduce_sum(e5_c2))\n",
    "    #tf.summary.scalar(\"de_dc1\", tf.reduce_sum(de_dc1))\n",
    "\n",
    "\n",
    "    # decoding - upsampling \n",
    "    # decoding level 1   \n",
    "    sliced = tf.slice(e4_c3, [0,0,0,0],[-1, deOut[1], deOut[2],-1])\n",
    "    de1_c1 = conv(tf.concat([sliced, de_dc1], 3), [f,f,1024,512], \"de1_c1\", \"SAME\")\n",
    "    de1_c2 = conv(de1_c1, [f,f,512,512], \"de1_c2\", \"SAME\")\n",
    "    deOut = [bsize, de1_c2.get_shape()[1].value*STRIDE, de1_c2.get_shape()[2].value*STRIDE, 256]\n",
    "    de1_dc1 = deconv(de1_c2, deOut, [f,f, 256, 512],  \"de1_dc1\")\n",
    "    #de1_dc1 = pixelDeconv.pixel_dcl(de1_c2, 256, [f,f], \"de1_dc1\")\n",
    "    \n",
    "    # decoding level 2 \n",
    "    sliced = tf.slice(e3_c3, [0,0,0,0],[-1, deOut[1], deOut[2],-1]) \n",
    "    de2_c1 = conv(tf.concat([sliced, de1_dc1], 3), [f,f,512,256], \"de2_c1\", \"SAME\")\n",
    "    de2_c2 = conv(de2_c1, [f,f,256,256], \"de2_c2\", \"SAME\")\n",
    "    deOut = [bsize, de2_c2.get_shape()[1].value*STRIDE, de2_c2.get_shape()[2].value*STRIDE, 128]\n",
    "    de2_dc1 = deconv(de2_c2, deOut, [f,f, 128, 256], \"de2_dc1\")\n",
    "    #de2_dc1 = pixelDeconv.pixel_dcl(de2_c2, 128, [f,f], \"de2_dc1\")\n",
    "    \n",
    "    # decoding level 3 \n",
    "    sliced = tf.slice(e2_c2, [0,0,0,0],[-1, deOut[1], deOut[2], -1]) \n",
    "    de3_c1 = conv(tf.concat([sliced, de2_dc1], 3), [f,f,256,128], \"de3_c1\", \"SAME\")\n",
    "    de3_c2 = conv(de3_c1, [f,f,128,128], \"de3_c2\", \"SAME\")\n",
    "    deOut = [bsize, de3_c2.get_shape()[1].value*STRIDE, de3_c2.get_shape()[2].value*STRIDE, 64]\n",
    "    de3_dc1 = deconv(de3_c2,deOut, [f,f, 64, 128],  \"de3_dc1\")\n",
    "    #de3_dc1 = pixelDeconv.pixel_dcl(de3_c2, 64, [f,f], \"de3_dc1\")\n",
    "    \n",
    "    # decoding level 3 \n",
    "    sliced = tf.slice(e1_c2, [0,0,0,0],[-1, deOut[1], deOut[2],-1]) \n",
    "    de4_c1 = conv(tf.concat([sliced, de3_dc1], 3), [f,f,128,64], \"de4_c1\", \"SAME\")\n",
    "    de4_c2 = conv(de4_c1, [f,f,64,64], \"de4_c2\", \"SAME\")\n",
    "    de4_c3 = conv(de4_c2, [f,f,64,64], \"de4_c3\", \"SAME\")\n",
    "    de4_c4 = conv(de4_c3, [f,f,64,64], \"de4_c4\", \"SAME\")\n",
    "\n",
    "    final = conv(de4_c4, [1,1,64,classes], \"final\", \"SAME\")\n",
    "    #tf.summary.scalar(\"final\", tf.reduce_sum(final))\n",
    "\n",
    "    softmax = tf.nn.softmax(final)\n",
    "\n",
    "    return final, tf.argmax(softmax, axis=3), softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(sess, data, config):\n",
    "\n",
    "        # Main Variables\n",
    "       \n",
    "        # create placeholder later to be filled\n",
    "        imageShape = [config[\"batchSize\"], data.config[\"y\"], data.config[\"x\"], data.config[\"imageChannels\"]]\n",
    "        image = tf.placeholder(tf.float32, shape=imageShape, name=\"input_image\")\n",
    "\n",
    "        labelsShape = [config[\"batchSize\"], data.config[\"y\"], data.config[\"x\"]]\n",
    "        labels = tf.placeholder(tf.int32, labelsShape, name=\"labels\")\n",
    "\n",
    "        # class Weights for class imbalance\n",
    "        # create weights for the particular batch\n",
    "        \n",
    "        onehot_labels = tf.one_hot(labels, data.config[\"classes\"])\n",
    "        weights = onehot_labels * data.config[\"classWeights\"] \n",
    "        weights = tf.reduce_sum(weights, 3)\n",
    "\n",
    "        # Neural Network is loaded from an extra file whose name is specified in the config file\n",
    "        logits, predictionNet, softmaxNet = net(image, data.config[\"classes\"])\n",
    "\n",
    "        # Training part\n",
    "        # sparse because labels are given as in only the correct class has the value 1 and the rest are zeros\n",
    "        loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits,weights=weights))\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "        # Set a learn rate variable for later configuration\n",
    "        LR = tf.Variable(config[\"learningRate\"], name=\"learningRate\")\n",
    "        tf.summary.scalar(\"learning_rate\", LR)\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=LR, name=\"AdamOpt\")\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.Variable(0, trainable=False))\n",
    "        \n",
    "        # metric variables for train pixel accuracy\n",
    "        correct_prediction = tf.equal(tf.cast(predictionNet, tf.int32), labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # Tensorflow dataset for a more efficient input pipeline by using threads\n",
    "        labelData = None\n",
    "        imgData = None\n",
    "        with tf.device('/cpu:0'):\n",
    "            iterators = []\n",
    "            for _type in [\"train\", \"validation\", \"test\"]:\n",
    "\n",
    "                print(\"Creating \", _type, \" dataset...\")\n",
    "                imageFilenames = tf.constant(data.imageData[_type])\n",
    "                labelsFileNames = tf.constant(data.imageData[_type+\"Label\"])\n",
    "\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((imageFilenames, imageFilenames))\n",
    "                dataset = dataset.map(lambda filename, label: tf.py_func(\n",
    "                                              data.getImageTuple,\n",
    "                                              [filename, label],\n",
    "                                              [tf.float32, tf.uint8]\n",
    "                                           ),  num_parallel_calls=config[\"threadCount\"])\n",
    "                if _type == \"train\":\n",
    "                    dataset = dataset.shuffle(buffer_size=int(100/config[\"batchSize\"]))\n",
    "                \n",
    "                dataset = dataset.batch(config[\"batchSize\"])\n",
    "                dataset = dataset.prefetch(4)\n",
    "                dataset = dataset.repeat(config[\"epochs\"])\n",
    "                iterators.append(dataset.make_one_shot_iterator())\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"logits\":logits,\n",
    "            \"loss\": loss,\n",
    "            \"prediction\": predictionNet,\n",
    "            \"softmaxOut\": softmaxNet,\n",
    "            \"learningRate\": LR,\n",
    "            \"imagePlaceholder\": image,\n",
    "            \"labelPlaceholder\": labels,\n",
    "            \"trainOp\": train_op,\n",
    "            \"preFetchIterators\": iterators,\n",
    "            \"accuracy\": accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: https://github.com/Aequalitas\n",
    "# This class provides some utility functions to work with a dataset\n",
    "import sys \n",
    "import random\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "class Data:\n",
    "\n",
    "    # loads all the in the dataset config file specified file names or the serialized numpy object\n",
    "    def loadDataset(self):\n",
    "        # set dictonary for the different dataset splits and set initially the dataset path\n",
    "        self.pathImages = {\n",
    "            \"train\": self.config[\"path\"],\n",
    "            \"trainLabel\": self.config[\"path\"],\n",
    "            \"test\" : self.config[\"path\"],\n",
    "            \"testLabel\": self.config[\"path\"],\n",
    "            \"validation\": self.config[\"path\"],\n",
    "            \"validationLabel\": self.config[\"path\"]\n",
    "        }\n",
    "        \n",
    "        # append the given train or label path\n",
    "        self.pathImages[\"train\"] += self.config[\"images\"]\n",
    "        self.pathImages[\"trainLabel\"] += self.config[\"labels\"]\n",
    "        self.pathImages[\"test\"] += self.config[\"images\"]\n",
    "        self.pathImages[\"testLabel\"] += self.config[\"labels\"]\n",
    "        self.pathImages[\"validation\"] += self.config[\"images\"]\n",
    "        self.pathImages[\"validationLabel\"] += self.config[\"labels\"]\n",
    "        \n",
    "        # with os.listdir() read the file names in the directories\n",
    "        trainDataFiles = trainImgFileNames#os.listdir(self.pathImages[\"train\"])\n",
    "        trainLabelDataFiles = trainDataFiles #os.listdir(self.pathImages[\"trainLabel\"])\n",
    "\n",
    "        # sort file names because os.listdir does extract them in arbitrary order\n",
    "        #trainDataFiles.sort()\n",
    "        #trainLabelDataFiles.sort()\n",
    "\n",
    "        # count the amount of the file names that also sets the training size\n",
    "        trainElements = int(self.config[\"trainSize\"]*len(trainDataFiles))\n",
    "        testElements = int(self.config[\"testSize\"]*len(trainDataFiles))\n",
    "\n",
    "        # remove n elements in order for a complete last batch with axis = 0 => batchSize\n",
    "        trainElements -= trainElements % self.config[\"batchSize\"]\n",
    "        testElements -= testElements % self.config[\"batchSize\"]\n",
    "\n",
    "        # shuffle the file names for creating a balanced training experience\n",
    "        # same random seed to be able to compare results with other training sessions\n",
    "        # here the sum of chars in the dataset name. Calc function taken from: https://codereview.stackexchange.com/q/13863\n",
    "        random.seed(sum(ord(c) - 64 for c in self.config[\"name\"]))\n",
    "        randomIndices = np.arange(len(trainDataFiles), dtype=np.int32)\n",
    "        random.shuffle(randomIndices)\n",
    "        trainDataFiles = np.take(trainDataFiles, randomIndices)\n",
    "        trainLabelDataFiles = np.take(trainLabelDataFiles, randomIndices)\n",
    "\n",
    "        # set the given dataset split whith their element by simple numpy indexing\n",
    "        self.imageData = {\n",
    "            \"train\": trainDataFiles[:trainElements],\n",
    "            \"trainLabel\": trainLabelDataFiles[:trainElements],\n",
    "            \"test\": trainDataFiles[trainElements:trainElements+testElements],\n",
    "            \"testLabel\": trainLabelDataFiles[trainElements:trainElements+testElements],\n",
    "            \"validation\": trainDataFiles[trainElements+testElements if testElements > 0 else trainElements:],\n",
    "            \"validationLabel\": trainLabelDataFiles[trainElements+testElements if testElements > 0 else trainElements:]\n",
    "        }\n",
    "        # set the dataset splits sizes\n",
    "        self.config[\"trainSize\"] = len(self.imageData[\"train\"])\n",
    "        self.config[\"testSize\"] = len(self.imageData[\"test\"])\n",
    "        self.config[\"validationSize\"] = len(self.imageData[\"validation\"])\n",
    "        print(\"trainSize: \", self.config[\"trainSize\"], \" Testsize: \", self.config[\"testSize\"], \"Validationsize: \", self.config[\"validationSize\"])\n",
    "\n",
    "    # string configPath - path of the json file which describes the dataset\n",
    "    def __init__(self, _config):\n",
    "        self.config = _config   \n",
    "       \n",
    "    \n",
    "        self.loadDataset()\n",
    "\n",
    "    # gets a value from the config file with its given name\n",
    "    def getConfig(self, name):\n",
    "        return self.config[name]\n",
    "    \n",
    "    # reads an image and pre-processes it for training/testing\n",
    "    # string imageFilename name(s) of the current train batch\n",
    "    # string labelFilename name(s) of the current label batch\n",
    "    def getImageTuple(self, imageFilename, labelFilename):\n",
    "        #print(imageFilename.decode())\n",
    "        img = getImageData(imageFilename.decode())\n",
    "        labelImg = getLabelData(labelFilename.decode())\n",
    "        \n",
    "        if self.config[\"downsize\"]:\n",
    "            img = cv2.resize(img, (self.config[\"x\"], self.config[\"y\"]), interpolation=cv2.INTER_NEAREST)\n",
    "            labelImg = cv2.resize(labelImg, (self.config[\"x\"], self.config[\"y\"]), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "        return img, labelImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(sess, config, data, graph):\n",
    "    imagePath = PATH+\"train_v2/0005d01c8.jpg\"\n",
    "\n",
    "    img = cv2.imread(imagePath)  \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #imgRes = cv2.resize(img, (data.config[\"x\"], data.config[\"y\"]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    imgRes = (imgRes - imgRes.mean()) / imgRes.std()\n",
    "    \n",
    "    inputData = np.expand_dims(imgRes, axis=0)\n",
    "    \n",
    "    if config[\"batchSize\"] > 1:\n",
    "        fillerArr = np.zeros((1,data.config[\"y\"], data.config[\"x\"], data.config[\"imageChannels\"]))\n",
    "        for x in range(config[\"batchSize\"]-1):\n",
    "            inputData = np.concatenate((inputData, fillerArr), axis=0)\n",
    "  \n",
    "    feed_dict = {\n",
    "            graph[\"imagePlaceholder\"]: inputData \n",
    "        }\n",
    "                       \n",
    "    predClasses = sess.run(graph[\"prediction\"], feed_dict=feed_dict)\n",
    "    predClasses = predClasses[0].reshape(data.config[\"x\"]*data.config[\"y\"]).astype(np.uint8)\n",
    "    display(Image.fromarray(predClasses, \"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: https://github.com/Aequalitas/\n",
    "# This file contains the training routine\n",
    "# One epoch is trained and at the end the validation set is evaluated\n",
    "\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "def doTrain(epoch, sess, graph, config, data, modelFileName):\n",
    "\n",
    "    step = 1\n",
    "    loss = []\n",
    "    train_acc = []\n",
    "    acc = []\n",
    "    epochSize = int(data.config[\"trainSize\"]/config[\"batchSize\"])\n",
    "    iterator = graph[\"preFetchIterators\"][0]\n",
    "    nextImgData = iterator.get_next()\n",
    "  \n",
    "    for batchIdx in range(epochSize):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            imgData  = sess.run(nextImgData)\n",
    "            # in case the last rest does not fit into a batch\n",
    "            if imgData[0].shape[0] == config[\"batchSize\"]:\n",
    "                _imageData = imgData[0]\n",
    "                _labelData = imgData[1]\n",
    "            else:\n",
    "                break       \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "        feed_dict = {\n",
    "            graph[\"imagePlaceholder\"] : _imageData,\n",
    "            graph[\"labelPlaceholder\"] : _labelData\n",
    "        }\n",
    "\n",
    "        # main train operation \n",
    "        graph[\"trainOp\"].run(feed_dict=feed_dict)\n",
    "        end = time.time() \n",
    "        \n",
    "        # print the train status every 10% of the train steps\n",
    "        #if step % 100 == 0: #int((epochSize)/10) == 0:\n",
    "        _loss, _train_acc = sess.run([graph[\"loss\"], graph[\"accuracy\"]], feed_dict=feed_dict)\n",
    "        train_acc.append(_train_acc*100)\n",
    "        loss.append(_loss)\n",
    "        status = \"Epoch: \"+str(epoch)+\" || Step: \"+str(step)+\"/\"+ str(epochSize)\n",
    "        status += \" || loss: \"+str(round(np.mean(np.array(loss)), 5))+\" || train_acc: \"+ str(round(np.mean(np.array(train_acc)), 5))\n",
    "        status += \"% || ETA: \"+str(datetime.timedelta(seconds=((end-start)*((epochSize)-step))))\n",
    "        # ends with \\r to delete the older line so the new line can be printed thus only one line is present at a time\n",
    "        print(status, end=\"\\r\")\n",
    "\n",
    "        if step >= epochSize:\n",
    "            break\n",
    "\n",
    "        step+=1\n",
    "\n",
    "    # validate trained model after one epoch\n",
    "    iterator = graph[\"preFetchIterators\"][1]\n",
    "    nextImgData = iterator.get_next()\n",
    "    valSize = int(data.config[\"validationSize\"]/config[\"batchSize\"])\n",
    "    for r in range(valSize):\n",
    "        imgData  = sess.run(nextImgData)\n",
    "        if imgData[0].shape[0] == config[\"batchSize\"]:\n",
    "            feed_dict={\n",
    "                graph[\"imagePlaceholder\"]: np.expand_dims(imgData[0], axis=3) if data.config[\"imageChannels\"] == 1 else imgData[0],\n",
    "                graph[\"labelPlaceholder\"]: imgData if data.config[\"imageChannels\"] == 1 else imgData[1]\n",
    "            }\n",
    "            _acc = 100*(graph[\"accuracy\"].eval(feed_dict=feed_dict))    \n",
    "            acc.append(_acc)\n",
    "\n",
    "    acc = round(np.mean(np.array(acc)), 5)\n",
    "    print(\"\\nvalidation_accuracy: \"+str(acc))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSize:  38300  Testsize:  212 Validationsize:  4044\n",
      "Creating  train  dataset...\n",
      "Creating  validation  dataset...\n",
      "Creating  test  dataset...\n",
      "Starting training...\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"neuralNetwork\":\"uNet\",\n",
    "    \"batchSize\":4,\n",
    "    \"threadCount\":8,\n",
    "    \"learningRate\":0.01,\n",
    "    \"steps\":9999999,\n",
    "    \"epochs\":40\n",
    "} \n",
    "\n",
    "dataConfig = {\n",
    "    \"x\": 256,\n",
    "    \"y\": 256,\n",
    "    \"imageChannels\": 3,\n",
    "    \"batchSize\":4,\n",
    "    \"tfPrefetch\":True,\n",
    "    \"downsize\":True,\n",
    "    \"name\":\"Airbus\",\n",
    "    \"classWeights\":[0.01, 1.0],\n",
    "    \"classes\":2,\n",
    "    \"path\":PATH,\n",
    "    \"images\":\"train_v2/\",\n",
    "    \"labels\":\"train_v2/\",\n",
    "    \"trainSize\":0.9,\n",
    "    \"testSize\":0.005\n",
    "    \n",
    "}\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "# GPU configuration\n",
    "tfConfig = tf.ConfigProto()\n",
    "\n",
    "with tf.Session(config=tfConfig) as sess:\n",
    "    data = Data(dataConfig)\n",
    "    # create the static tensorflow graph\n",
    "    graph = buildGraph(sess, data, config)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    modelFileName = \"DAS\"\n",
    "    print(\"Starting training...\")\n",
    "    best_acc = 0\n",
    "    LRcounter = 0\n",
    "    bestMeanIoU = 0\n",
    "    for e in range(1, config[\"epochs\"]+1):\n",
    "        curr_acc = doTrain(e, sess, graph, config, data, modelFileName)\n",
    "        predict(sess, config, data, graph)\n",
    "        # if validation accuracy is not increasing after 4 times then decrease the learning rate by multiple of 0.1\n",
    "        if best_acc < curr_acc:\n",
    "            print(\"val acc of \", curr_acc, \" better than \", best_acc)\n",
    "            best_acc = curr_acc\n",
    "            LRcounter = 0\n",
    "        else:\n",
    "            print(\"val acc of \", curr_acc, \" NOT better than \", best_acc)\n",
    "            if LRcounter >= 4:\n",
    "                lr = graph[\"learningRate\"].eval()\n",
    "                graph[\"learningRate\"] = tf.assign(graph[\"learningRate\"], lr*0.1)\n",
    "                print(\"Learning rate of \", lr ,\" is now decreased to \", lr * 0.1)\n",
    "                LRcounter = 0\n",
    "\n",
    "            LRcounter = LRcounter + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
